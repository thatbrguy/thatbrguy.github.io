---
---

@article{upfusion2023,
  author    = {Nagoor Kani, Bharath Raj and Lee, Hsin-Ying and Tulyakov, Sergey and Tulsiani, Shubham},
  title     = {UpFusion: Novel View Diffusion from Unposed Sparse View Observations},
  journal   = {arXiv preprint arXiv:2312.06661},
  year      = {2023},
  preview   = {ITW_lock.gif},
  html      = {https://upfusion3d.github.io/},
  selected={true},
  abstract  = {
    We propose UpFusion, a system that can perform novel view synthesis and infer 3D representations for an object given a sparse set of reference images without corresponding pose information. Current sparse-view 3D inference methods typically rely on camera poses to geometrically aggregate information from input views, but are not robust in-the-wild when such information is unavailable/inaccurate. In contrast, UpFusion sidesteps this requirement by learning to implicitly leverage the available images as context in a conditional generative model for synthesizing novel views. We incorporate two complementary forms of conditioning into diffusion models for leveraging the input views: a) via inferring query-view aligned features using a scene-level transformer, b) via intermediate attentional layers that can directly observe the input image tokens. We show that this mechanism allows generating high-fidelity novel views while improving the synthesis quality given additional (unposed) images. We evaluate our approach on the Co3Dv2 and Google Scanned Objects datasets and demonstrate the benefits of our method over pose-reliant sparse-view methods as well as single-view methods that cannot leverage additional views. Finally, we also show that our learned model can generalize beyond the training categories and even allow reconstruction from self-captured images of generic objects in-the-wild.

  }
}

@article{skeletons2020,
  title={Exploring Techniques to Improve Activity Recognition using Human Pose Skeletons},
  journal={2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)},
  author={N., Bharath Raj and Subramanian, Anand and Ravichandran, Kashyap and N., Venkateswaran},
  selected={true},
  preview={poster_human_pose.png},
  html={https://ieeexplore.ieee.org/document/9096918},
  abstract={
    Human pose skeletons provide an explainable representation of the orientation of a person. Neural network architectures such as OpenPose can estimate the 2D human pose skeletons of people present in an image with good accuracy. Naturally, the human pose is a very attractive choice as a representation for building systems aimed at human activity recognition. However, raw pose keypoint representations suffer from various problems such as variance to translation and scale of the input images. Keypoints are also often missed by the pose estimation framework. These, and other factors lead to poor generalization and learning of networks that may be trained directly on these raw representations. This paper introduces various methods aimed at building a robust representation for training models related to activity recognition tasks, such as the usage of handcrafted features extracted from poses with the intent of introducing scale and translation invariance. Additionally, the usage of train-time techniques such as keypoint dropout are explored to facilitate better learning of models. Finally, we conduct an ablation study comparing the performance of deep learning models trained on raw keypoint representation and handcrafted features whilst incorporating our train-time techniques to quantify the effectiveness of our introduced methods over raw representations.
  }
}

@article{dehaze2018,
  title={Single Image Haze Removal using a Generative Adversarial Network},
  journal={2020 International Conference on Wireless Communications Signal Processing and Networking (WiSPNET)},
  author={N., Bharath Raj and N., Venkateswaran},
  selected={true},
  preview={dehaze_img.png},
  html={https://arxiv.org/abs/1810.09479},
  abstract={Traditional methods to remove haze from images rely on estimating a transmission map. When dealing with single images, this becomes an ill-posed problem due to the lack of depth information. In this paper, we propose an end-to-end learning based approach which uses a modified conditional Generative Adversarial Network to directly remove haze from an image. We employ the usage of the Tiramisu model in place of the classic U-Net model as the generator owing to its higher parameter efficiency and performance. Moreover, a patch based discriminator was used to reduce artefacts in the output. To further improve the perceptual quality of the output, a hybrid weighted loss function was designed and used to train the model. Experiments on synthetic and real world hazy images demonstrates that our model performs competitively with the state of the art methods. }
}

@article{ppm2023,
  title={Progressive Photon Mapping},
  journal={Project Submission for Physics-based Rendering},
  project={true},
  year={2023},
  month={},
  preview={rendering_competition.png},
  html={https://docs.google.com/presentation/d/1cFIaJfL7QlMz9YKi79IUk4ldDE-msTSUDFaXR7SNyKk/edit?usp=sharing},
  abstract={In this project, I experimented with adding features to a custom version of the DIRT package such that a swimming pool could be rendered with realistic caustic effects. The current integrators in DIRT cannot render such scene realistically due to presense of paths of type ùêø(ùëÜ+)ùê∑(ùëÜ+). To overcome this issue, I added support for photon mapping in DIRT and experimented with adding enhancements to the base photon mapping algorithm. I also add support for progressive photon mapping, an approach that should reduce the artefacts that are typically observed with photon mapping. In addition to the above, I have also added support for the GGX BRDF and a directional light source.}
}

@article{jetsontinyyolo,
  title={Deploying Tiny YOLOv2 on Jetson Nano using DeepStream},
  journal={Featured in Jetson Community Resources (Deep Learning section)},
  project={true},
  preview={jetson.jpeg},
  year={},
  month={},
  html={https://developer.nvidia.com/embedded/community/resources/#deep_learning},
  abstract={
    In this project, I experimented with deploying a Tiny YOLOv2 ONNX model on NVIDIA Jetson Nano using the DeepStream SDK. To this end, I modified existing C++ code to enable it to parse the output of the TinyYOLOv2 model.
  }
}

@string{aps = {American Physical Society,}}

@book{einstein1956investigations,
  bibtex_show={true},
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  journal={American Journal of Physics},
  year={1956},
  publisher={Courier Corporation},
  preview={brownian-motion.gif}
}

@article{einstein1950meaning,
  abbr={AJP},
  bibtex_show={true},
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers}
}

@article{PhysRev.47.777,
  abbr={PhysRev},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein, A. and Podolsky, B. and Rosen, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf},
  altmetric={248277},
  dimensions={true},
  preview={brownian-motion.gif}
}

@article{einstein1905molekularkinetischen,
  title={{\"U}ber die von der molekularkinetischen Theorie der W{\"a}rme geforderte Bewegung von in ruhenden Fl{\"u}ssigkeiten suspendierten Teilchen},
  author={Einstein, A.},
  journal={Annalen der physik},
  volume={322},
  number={8},
  pages={549--560},
  year={1905},
  publisher={Wiley Online Library}
}

@article{einstein1905movement,
  abbr={Ann. Phys.},
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.},
  volume={17},
  pages={549--560},
  year={1905}
}

@article{einstein1905electrodynamics,
  title={On the electrodynamics of moving bodies},
  author={Einstein, A.},
  year={1905}
}

@book{przibram1967letters,
  bibtex_show={true},
  title={Letters on wave mechanics},
  author={Einstein, Albert and Schr√∂dinger, Erwin and Planck, Max and Lorentz, Hendrik Antoon and Przibram, Karl},
  year={1967},
  publisher={Vision},
  preview={wave-mechanics.gif}
}

@article{einstein1905movement,
  abbr={Ann. Phys.},
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.},
  volume={17},
  pages={549--560},
  year={1905},
}

@article{einstein1905electrodynamics,
  title={On the electrodynamics of moving bodies},
  author={Einstein, A.},
  year={1905},
}

